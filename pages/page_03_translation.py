import streamlit as st
import base64
import google.auth
from google.oauth2 import service_account
import google.auth.transport.requests
import vertexai
from vertexai.generative_models import GenerativeModel, Part, FinishReason
import vertexai.preview.generative_models as generative_models
from auth import login, logout
from components import chinese_version_link, save_invite_code, vibtitle_link

st.set_page_config(
    page_title="GCP GenAI",
    page_icon="üëã",
)

save_invite_code()

if not login():
    st.stop()

with st.sidebar:
    st.markdown(chinese_version_link(), unsafe_allow_html=True)
    st.markdown(f"""
        <div style="background-color: #d4edda; border-color: #c3e6cb; color: #155724; 
                    padding: 10px; border-radius: 0.25rem; text-align: center; margin-bottom: 10px;">
            <p style="margin-bottom: 0;">Welcome!</p>
        </div>
    """, unsafe_allow_html=True)
    left_co, cent_co,last_co = st.columns([0.35,0.33,0.32])
    with cent_co:
        if st.button("log out"):
            logout()

credentials_info = st.secrets["GOOGLE_APPLICATION_CREDENTIALS"]

creds = service_account.Credentials.from_service_account_info(
    credentials_info,
    scopes=["https://www.googleapis.com/auth/cloud-platform"]
)

auth_req = google.auth.transport.requests.Request()
creds.refresh(auth_req)

vertexai.init(project="lwk-genai-test", location="us-central1", credentials=creds)

# Streamlit application interface
left_co, cent_co,last_co = st.columns([0.35,0.35,0.3])
with cent_co:
    st.title(":blue[GCP Gen]:rainbow[AI]")
left_co, cent_co,last_co = st.columns([0.34,0.56,0.1])
with cent_co:
    st.caption(":blue[_Enterprise-ready Translation Platform_]")
st.image('https://storage.googleapis.com/ghackathon/page_3.png')
left_co, cent_co,last_co = st.columns([0.24,0.51,0.25])
with cent_co:
    st.subheader('', divider='rainbow')
    
# Define translation_option as a global variable
translation_option = None
    
# Streamlit sidebar interface
with st.sidebar:
    left_co, cent_co,last_co = st.columns([0.34,0.33,0.33])
    with cent_co:
        st.image('https://storage.googleapis.com/ghackathon/image2.gif')
    left_co, cent_co,last_co = st.columns([0.28,0.5,0.22])
    with cent_co:
        st.title(":blue[GCP Gen]:rainbow[AI]")
    temperature = st.slider("Adjust Model Temperature", min_value=0.0, max_value=2.0, value=1.0, help=(
        """
        Temperature is used for sampling during response generation, which occurs when applying topP and topK. Temperature controls the degree of randomness in token selection. For prompts that require less open-ended or creative responses, a lower temperature is good, while a higher temperature can lead to more diverse or creative results. A temperature of 0 means always selecting the highest probability token. In this case, the response for a given prompt is mostly deterministic, but there may still be some variation.
        
        If the model returns responses that are too generic, too short, or the model gives fallback responses, try increasing the temperature.
        """
    ))
    top_p = st.slider ("Adjust Model Top_p", min_value=0.00, max_value=1.00, value=0.95, help=(
        """
        Top-P changes how the model selects output tokens. Tokens are chosen from most likely to least likely (see top-K) until the sum of their probabilities equals the top-P value. For example, if tokens A, B, and C have probabilities 0.3, 0.2, and 0.1 respectively, and the top-P value is 0.5, the model will select the next token from A or B using temperature and discard C as a candidate.

        Specifying a lower value will result in less random responses, while specifying a higher value will result in more random responses.
        """
    ))
    st.subheader('',divider='rainbow')
    translation_option = st.selectbox(
    "Please select the target language for translation:",
    ("German", "French", "Spanish", "Portuguese", "Italian", "Russian", "Arabic", "Chinese", "Japanese", "Korean", "English"),
    index=None,
    placeholder="Please select a language")
    st.page_link("homepage.py", label="Home", icon="üè†")
    st.page_link("pages/page_01_text_generation.py", label="Text Generation", icon="üìñ")
    st.page_link("pages/page_13_prompt_generator.py", label="Prompt Generator", icon="‚ú®")
    st.page_link("pages/page_02_media_understanding.py", label="Media Understanding", icon="üéûÔ∏è")
    st.page_link("pages/page_03_translation.py", label="Text Translation", icon="üá∫üá≥")
    st.page_link("pages/page_04_travel_advisor.py", label="Travel Advisor", icon="‚úàÔ∏è")
    st.page_link("pages/page_05_rag_search.py", label="RAG Search", icon="üîç")
    st.page_link("pages/page_06_media_search.py", label="Media Search", icon="üé•")
    st.page_link("pages/page_07_image_generation.py", label="Image Generation", icon="üé®")
    st.page_link("pages/page_08_chatbot.py", label="Chatbot", icon="üí¨")
    st.page_link("pages/page_09_gaming_servicebot.py", label="Gaming Servicebot", icon="ü§ñ")
    st.page_link("pages/page_10_ecommerce_servicebot.py", label="E-commerce Servicebot", icon="ü§ñ")
    st.page_link("pages/page_11_claude_chatbot.py", label="Claude 3.5 Chatbot", icon="üí¨")
    st.page_link("pages/page_12_llama_chatbot.py", label="Llama 3.1 Chatbot", icon="üí¨")
    vibtitle_link()
    st.page_link("https://pantheon.corp.google.com/translation/hub", label="GCP Translation Hub", icon="üåé")
    st.page_link("https://pantheon.corp.google.com/vertex-ai/generative/multimodal/gallery", label="GCP Console - Gemini", icon="üåé")
    st.page_link("https://pantheon.corp.google.com/gen-app-builder/engines", label="GCP Console - App Builder", icon="üåé")
    st.text("")
    st.subheader('', divider='rainbow')
    st.text("")
    st.page_link("pages/page_14_user_manual.py", label="Demo Manual", icon="üß≠")
    st.markdown(
        """
    ## About
    This is a generative AI platform and enterprise-ready RAG search engine powered by :blue[Google Cloud Vertex AI]
        """
    )
    st.page_link("https://cloud.google.com/vertex-ai?hl=en", label="Google Cloud Vertex AI", icon="‚òÅÔ∏è")
    st.text("")
    st.text("")
    st.text("")
    st.text("")

    st.page_link("pages/terms_of_service.py", label="Terms of Service", icon="üìÑ")
    st.page_link("pages/privacy_policy.py", label="Privacy Policy", icon="üîí")

# Function of generating text
def generate_text(prompt):
  vertexai.init(project="lwk-genai-test", location="us-central1")
  model = GenerativeModel("gemini-1.5-flash-002")
  responses = model.generate_content(
      [prompt],
      generation_config=generation_config,
      safety_settings=safety_settings,
      stream=True,
  )

  generated_text = ""
  for response in responses:
    generated_text += response.text

  return generated_text

# Model parameters
generation_config = {
    "max_output_tokens": 8192,
    "temperature": temperature,
    "top_p": top_p,
}

safety_settings = {
    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.OFF,
    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.OFF,
    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.OFF,
    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.OFF,
}

# Streamlit interface
st.write("Please note: To help you distinguish the translation results, please choose either 'Upload Document' or 'Input Text'.")

uploaded_files = st.file_uploader("Please upload the documents you need to translate. You can select multiple documents to upload:", type=("txt"), accept_multiple_files=True)

prompt = st.text_area("Or input the text you need to translate:", "")

if uploaded_files:
    all_text = ""
    for uploaded_file in uploaded_files:
        bytes_data = uploaded_file.read()
        text = bytes_data.decode()
        all_text += text + "\n\n"
            

with st.form("myform"):
    left_co, cent_co,last_co = st.columns([0.42,0.29,0.29])
    with cent_co:
        submitted = st.form_submit_button("Start Translation")
    if uploaded_files and prompt and translation_option and submitted:
        st.error("To help you distinguish the translation results, please choose either 'Upload Document' or 'Input Text'.")
        
    if uploaded_files and prompt and submitted:
        st.error("To help you distinguish the translation results, please choose either 'Upload Document' or 'Input Text'.")
        
    if uploaded_files and submitted and not prompt and not translation_option:
        st.error("üëà Please select the language you want to translate to.")
        
    if prompt and submitted and not uploaded_files and not translation_option:
        st.error("üëà Please select the language you want to translate to.")
    
    if prompt and translation_option and submitted and not uploaded_files:
        prompt_without_article = f"Please translate the following text into {translation_option}, and output the translation result directly\n\n Text to be translated: \n{prompt}\n\nAnswer:"
        with st.spinner('Please wait :coffee: Almost done...'):
            generated_text = generate_text(prompt_without_article)
            st.write(generated_text)
            
    if uploaded_files and translation_option and submitted and not prompt:
        prompt_with_article = f"Please translate the following text into {translation_option}, and output the translation result directly\n\n Text to be translated: \n{all_text}\n\nAnswer:"
        with st.spinner('Please wait :coffee: Almost done...'):
            generated_text = generate_text(prompt_with_article)
            st.write(generated_text)


st.markdown("<div style='margin-bottom: 60px;'></div>", unsafe_allow_html=True)

st.markdown('''
    <style>
    .footer {
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        padding: 10px 0;
        margin-left: 11rem;
        text-align: center;
        z-index: 999;
        background-color: rgba(255, 255, 255, 0.5);
        color: black;
        backdrop-filter: blur(5px);
        -webkit-backdrop-filter: blur(5px);
    }
    
    @media (prefers-color-scheme: dark) {
        .footer {
            background-color: rgba(14, 17, 23, 0.8) !important;
            color: white !important;
            backdrop-filter: blur(5px) !important;
            -webkit-backdrop-filter: blur(5px) !important;
        }
    }
    </style>

    <script>
    document.addEventListener("DOMContentLoaded", function() {
        setTimeout(function() {
            const isDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
            const footer = document.querySelector('.footer');
            
            if (footer) {
                if (isDark) {
                    footer.style.backgroundColor = 'rgba(14, 17, 23, 0.8)';
                    footer.style.color = 'white';
                    footer.style.backdropFilter = 'blur(5px)';
                    footer.style.webkitBackdropFilter = 'blur(5px)';
                } else {
                    footer.style.backgroundColor = 'rgba(255, 255, 255, 0.5)';
                    footer.style.color = 'black';
                    footer.style.backdropFilter = 'blur(5px)';
                    footer.style.webkitBackdropFilter = 'blur(5px)';
                }
            }
            
            if (window.matchMedia) {
                window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', function(e) {
                    const isDarkNow = e.matches;
                    const footerNow = document.querySelector('.footer');
                    
                    if (footerNow) {
                        if (isDarkNow) {
                            footerNow.style.backgroundColor = 'rgba(14, 17, 23, 0.8)';
                            footerNow.style.color = 'white';
                            footerNow.style.backdropFilter = 'blur(5px)';
                            footerNow.style.webkitBackdropFilter = 'blur(5px)';
                        } else {
                            footerNow.style.backgroundColor = 'rgba(255, 255, 255, 0.5)';
                            footerNow.style.color = 'black';
                            footerNow.style.backdropFilter = 'blur(5px)';
                            footerNow.style.webkitBackdropFilter = 'blur(5px)';
                        }
                    }
                });
            }
        }, 500);
    });
    </script>
''', unsafe_allow_html=True)

# footer HTML
st.markdown('''
    <div class="footer">
      <div class="footer-content">
        <p style="margin: 0;">
          <span>¬© LWK &nbsp;&nbsp;|&nbsp;&nbsp Designed &amp; Developed by 
            <a href="{developer_profile_link}" style="text-decoration: underline; font-weight: bold;">{developer_name}</a>
          </span>
          <span> &nbsp;&nbsp;|&nbsp;&nbsp Powered by </span>
          <img src="https://storage.googleapis.com/ghackathon/GoogleCloud_logo_36px.png" alt="Logo" style="height: 18px; vertical-align: middle; margin: 0 2px; transform: translateY(-1px);">
          <span>Vertex AI</span>
        </p>
      </div>
    </div>
'''.format(
    developer_profile_link=st.secrets["developer_profile_link"],
    developer_name=st.secrets["developer_name"]
), unsafe_allow_html=True)